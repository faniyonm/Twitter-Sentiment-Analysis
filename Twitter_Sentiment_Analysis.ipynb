{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrBpGhtvyvPt3jouaR0h6S",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/faniyonm/Twitter-Sentiment-Analysis/blob/main/Twitter_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Twitter Sentiment Analysis\n"
      ],
      "metadata": {
        "id": "wBrzpl7seDcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Sentiment140 dataset is a large collection of 1.6 million tweets labeled for sentiment analysis. It provides a foundation for training and evaluating models that classify tweets as positive, negative, or neutral. Researchers and businesses use it to study public opinion, brand perception, and social trends at scale. With Python libraries like Pandas, and scikit-learn, we can easily load, clean, and analyze this dataset to build sentiment analysis models efficiently."
      ],
      "metadata": {
        "id": "secE146geOIh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "m4eirAdgc_qt"
      },
      "outputs": [],
      "source": [
        "#Libraries\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.metrics import accuracy_score, classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Dataset\n",
        "The Sentiment140 dataset is accessed using Pandas which allows us to directly load the dataset from a CSV file into a DataFrame. We keep only the polarity column (which shows the sentiment label: 0 for negative, 2 for neutral, 4 for positive) and the tweet text column (which contains the tweet content)."
      ],
      "metadata": {
        "id": "o1MNso4zfxvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('training.1600000.processed.noemoticon.csv', encoding='latin-1', header=None,engine='python',on_bad_lines=\"skip\")\n",
        "df = df[[0, 5]]\n",
        "df.columns = ['polarity', 'text']\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-JFNnzIf342",
        "outputId": "4998882f-6cd6-49d1-ec88-b6cfeeef4999"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   polarity                                               text\n",
            "0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1         0  is upset that he can't update his Facebook by ...\n",
            "2         0  @Kenichan I dived many times for the ball. Man...\n",
            "3         0    my whole body feels itchy and like its on fire \n",
            "4         0  @nationwideclass no, it's not behaving at all....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Positive and Negative Sentiments\n",
        "Here we remove neutral tweets where polarity is 2, map the labels so 0 stays negative and 4 becomes 1 for positive. Then we print how many positive and negative tweets are left in the data."
      ],
      "metadata": {
        "id": "olzhJa0NiBiM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df.polarity != 2]\n",
        "\n",
        "df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n",
        "\n",
        "print(df['polarity'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QPn4SCxCikSX",
        "outputId": "897dd83c-b29d-4374-e996-9659528823db"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "polarity\n",
            "0    800000\n",
            "1    800000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Cleaning the Tweets\n",
        "We create a simple function to convert all text to lowercase for consistency, apply it to every tweet in the dataset, and then display the original and cleaned versions of the first few tweets."
      ],
      "metadata": {
        "id": "EyCijrmeiyLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    return text.lower()\n",
        "\n",
        "df['clean_text'] = df['text'].apply(clean_text)\n",
        "\n",
        "print(df[['text', 'clean_text']].head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3NlKgeyci4d8",
        "outputId": "ac282e98-a82d-4b7c-f25e-8c8f7ce6797a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  @switchfoot http://twitpic.com/2y1zl - Awww, t...   \n",
            "1  is upset that he can't update his Facebook by ...   \n",
            "2  @Kenichan I dived many times for the ball. Man...   \n",
            "3    my whole body feels itchy and like its on fire    \n",
            "4  @nationwideclass no, it's not behaving at all....   \n",
            "\n",
            "                                          clean_text  \n",
            "0  @switchfoot http://twitpic.com/2y1zl - awww, t...  \n",
            "1  is upset that he can't update his facebook by ...  \n",
            "2  @kenichan i dived many times for the ball. man...  \n",
            "3    my whole body feels itchy and like its on fire   \n",
            "4  @nationwideclass no, it's not behaving at all....  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the Data for Modeling"
      ],
      "metadata": {
        "id": "OTqyC2NPjgX4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train Test Split\n",
        "We split the clean_text and polarity columns into training and testing sets."
      ],
      "metadata": {
        "id": "fl2UbLWFj41q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df['clean_text'],\n",
        "    df['polarity'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"Train size:\", len(X_train))\n",
        "print(\"Test size:\", len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0TQXmCJkF8V",
        "outputId": "3d5f9ef2-5d86-4656-e385-d6db56856459"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train size: 1280000\n",
            "Test size: 320000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perform Vectorization\n",
        "We create a TF-IDF vectorizer that converts text into numerical features using unigrams and bigrams, limited to 5000 features. It is fitted and transformed on the training data, then applied to the test data. Finally, we print the shapes of the resulting TF-IDF matrices."
      ],
      "metadata": {
        "id": "DtRkQ0m4kQYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features=5000, ngram_range=(1,2))\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF shape (test):\", X_test_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8rWR-pvkZxd",
        "outputId": "6e6faf78-5221-4173-e689-838a49487080"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-IDF shape (train): (1280000, 5000)\n",
            "TF-IDF shape (test): (320000, 5000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fitting Different Models\n",
        "We train different machine learning models on the data, including Bernoulli Naive Bayes, Support Vector Machine (SVM), and Logistic Regression, to compare their performance on the sentiment classification task."
      ],
      "metadata": {
        "id": "WfvbrkwplMtm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Logistic Regression\n",
        "We train a Logistic Regression model with up to 100 iterations on the TF-IDF features. The model then predicts sentiment labels for the test data, and we print the accuracy along with a detailed classification report for evaluation."
      ],
      "metadata": {
        "id": "ogGaYhC2lc4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "logreg = LogisticRegression(max_iter=100)\n",
        "logreg.fit(X_train_tfidf, y_train)\n",
        "\n",
        "logreg_pred = logreg.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, logreg_pred))\n",
        "print(\"\\nLogistic Regression Classification Report:\\n\", classification_report(y_test, logreg_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HcL5N0PalYVO",
        "outputId": "878274e7-6df2-40bb-ec5f-c928ee56e7e9"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Accuracy: 0.79539375\n",
            "\n",
            "Logistic Regression Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Logistic Regression model achieved an accuracy of 79.5%. The classification report shows balanced performance, with precision, recall, and F1-scores around 0.80 for both negative and positive classes, indicating the model is effective at distinguishing sentiment in tweets."
      ],
      "metadata": {
        "id": "MZ0iIBHnmd4f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Bernoulli Naive Bayes\n",
        "We train a Bernoulli Naive Bayes classifier on the TF-IDF features from the training data. The model then predicts sentiments for the test data, and we print the accuracy along with a detailed classification report for evaluation."
      ],
      "metadata": {
        "id": "qlidrWW1mM2l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bnb = BernoulliNB()\n",
        "bnb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "bnb_pred = bnb.predict(X_test_tfidf)\n",
        "\n",
        "print(\"Bernoulli Naive Bayes Accuracy:\", accuracy_score(y_test, bnb_pred))\n",
        "print(\"\\nBernoulliNB Classification Report:\\n\", classification_report(y_test, bnb_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nuB6Yc8Sm__p",
        "outputId": "1aadf7f0-34b3-40b7-9fa1-7a4528269cf0"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bernoulli Naive Bayes Accuracy: 0.766478125\n",
            "\n",
            "BernoulliNB Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.75      0.76    159494\n",
            "           1       0.76      0.78      0.77    160506\n",
            "\n",
            "    accuracy                           0.77    320000\n",
            "   macro avg       0.77      0.77      0.77    320000\n",
            "weighted avg       0.77      0.77      0.77    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bernoulli Naive Bayes model achieved an accuracy of 76.6%. The classification report shows fairly balanced performance, with precision, recall, and F1-scores around 0.76–0.77 for both classes, indicating the model performs reasonably well but slightly below Logistic Regression."
      ],
      "metadata": {
        "id": "fhAh8sJDnJKO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Support Vector Machine (SVM)\n",
        "We train a Support Vector Machine (SVM) model with a maximum of 1000 iterations on the TF-IDF features. The model then predicts sentiment labels for the test data, and we print the accuracy along with a detailed classification report to evaluate its performance."
      ],
      "metadata": {
        "id": "PVB34hzqnKtT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "svm = LinearSVC(max_iter=1000)\n",
        "svm.fit(X_train_tfidf, y_train)\n",
        "\n",
        "svm_pred = svm.predict(X_test_tfidf)\n",
        "\n",
        "print(\"SVM Accuracy:\", accuracy_score(y_test, svm_pred))\n",
        "print(\"\\nSVM Classification Report:\\n\", classification_report(y_test, svm_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hw24XS53ng_1",
        "outputId": "22fbd49e-0fa3-4214-ce85-3b39f5b4cc28"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM Accuracy: 0.79528125\n",
            "\n",
            "SVM Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.78      0.79    159494\n",
            "           1       0.79      0.81      0.80    160506\n",
            "\n",
            "    accuracy                           0.80    320000\n",
            "   macro avg       0.80      0.80      0.80    320000\n",
            "weighted avg       0.80      0.80      0.80    320000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Support Vector Machine (SVM) model achieved an accuracy of 79.5%. The classification report shows balanced precision, recall, and F1-scores around 0.79–0.80 for both negative and positive classes, indicating performance comparable to Logistic Regression."
      ],
      "metadata": {
        "id": "j0NwK47wn9z-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictions on sample Tweets\n",
        "Three sample tweets are taken and transformed into TF-IDF features using the same vectorizer. These features are then passed to the trained Logistic Regression BernoulliNaive Bayes, and SVM models to predict sentiment. The predictions are printed for each classifier, where 1 represents Positive and 0 represents Negative."
      ],
      "metadata": {
        "id": "npzgsvwBnn_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tweets = [\"I love this!\", \"I hate that!\", \"It was okay, not great.\"]\n",
        "sample_vec = vectorizer.transform(sample_tweets)\n",
        "\n",
        "print(\"\\nSample Predictions:\")\n",
        "print(\"Logistic Regression:\", logreg.predict(sample_vec))\n",
        "print(\"BernoulliNB:\", bnb.predict(sample_vec))\n",
        "print(\"SVM:\", svm.predict(sample_vec))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlHdxQbuo14S",
        "outputId": "b3fa5a4e-9af1-48c8-b27f-a47021ee1ff1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Sample Predictions:\n",
            "Logistic Regression: [1 0 1]\n",
            "BernoulliNB: [1 0 1]\n",
            "SVM: [1 0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All three models, Logistic Regression, Bernoulli Naive Bayes, and SVM, predicted the same results for the sample tweets: [1 0 1], meaning the first and third tweets were classified as Positive and the second tweet as Negative. We can see that our models are working fine and giving the same predictions even with different approaches."
      ],
      "metadata": {
        "id": "Jf03WvMapOZM"
      }
    }
  ]
}